---
title: "How well they do it"
author: "Xiaozhuo Wang"
date: "2017-09-18"
output: html_document
---
##https://catree1988.github.io/practicalmachinelearning/
Background
----------

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement ?C a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, we will use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants, who were asked to perform barbell lifts correctly and incorrectly in 5 different ways. The goal of our project is to predict the manner in which they did the exercise. More information and the data for this project come from this source: http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har

how you built your model
how you used cross validation
what you think the expected out of sample error is
why you made the choices you did
predict 20 different test cases

Data preparation
----------------

The training data for this project are available [here](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv), 
the test data are available [here](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv).

The manner in which they did the exercise is the "classe" variable in the training set. 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
## Loading data and packages
if(!file.exists("pml-training.csv")) {
        download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",
              "pml-training.csv")}
if(!file.exists("pml-training.csv")) {
        download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",
              "pml-testing.csv")}
pml_training <- read.csv("pml-training.csv")
pml_testing <- read.csv("pml-testing.csv")
library(caret)
```

When exploring the data with summary function, it can be found that there are plenty 
of colums filled with NAs or blanks, such variables are excluded. Some colums like 
row numbers, user names and time stamps are also excluded considering the goal of 
this project. Then the remained data are sliced into 70% for training and 30% for 
validing.

```{r, echo=FALSE, cache=TRUE}
## Data preprocessing
suma <- summary(pml_training)
isna <- NULL; for (i in 1:160) {isna[i] = sum(is.na(pml_training[,i])) == 19216}
isbl <- grepl(":19216",suma[1,])
iskept <- !(isna|isbl)
iskept[1:7] <- FALSE
pre_training <- pml_training[,iskept]
testing <- pml_testing[,iskept]

set.seed(2333)
inTrain <- createDataPartition(y = pre_training$classe, p = 0.7, list = FALSE)
training <- pre_training[inTrain,]
validing <- pre_training[-inTrain,]
dim(training); dim(validing); dim(testing)
```

Model biulding
--------------

In this project, three training methods are performed and compared to choose the 
best one: random forest (rf), boosting with trees (gbm) and quadratic discriminant 
analysis (qda). rf and gbm are chosen because of their high accuracy, qda is chosen 
because of reduced computational complexity (assumes multivariate Gaussian distribution 
with different covariance for predictor variables).

The rf model used train control with a 10-fold cross validation method to avoid 
over-fitting. Other parameters in model training are all by default of 'train' function 
of 'caret' package.

```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}
## Model training
fitControl <- trainControl(method = "cv", number = 10, allowParallel = TRUE)
set.seed(2333); t1 <- Sys.time()
mod_rf <- train(classe ~ ., data = training, method = "rf", 
                trControl = fitControl); t2 <- Sys.time()
mod_gbm <- train(classe ~ ., data = training, method = "gbm", verbose = FALSE, 
                 trControl = fitControl); t3 <- Sys.time()
mod_qda <- train(classe ~ ., data = training, method = "qda", 
                 trControl = fitControl); t4 <- Sys.time()

time_rf <- as.double(t2 - t1, units = "secs")
time_gbm <- as.double(t3 - t2, units = "secs")
time_qda <- as.double(t4 - t3, units = "secs")
time <- data.frame(round(rbind(rf = time_rf, gbm = time_gbm, qda = time_qda), 0))
time <- cbind(time,c("s","s","s"))
colnames(time) <- c("Time for training","")
time
```

Model validing
--------------



```{r, echo=FALSE}
## Model validing
insam_rf<- confusionMatrix(training$classe, predict(mod_rf, training))$overall
insam_gbm<- confusionMatrix(training$classe, predict(mod_gbm, training))$overall
insam_qda<- confusionMatrix(training$classe, predict(mod_qda, training))$overall
otsam_rf<- confusionMatrix(validing$classe, predict(mod_rf, validing))$overall
otsam_gbm<- confusionMatrix(validing$classe, predict(mod_gbm, validing))$overall
otsam_qda<- confusionMatrix(validing$classe, predict(mod_qda, validing))$overall
accuracy <- rbind(insam_rf, otsam_rf, insam_gbm, otsam_gbm, insam_qda, otsam_qda)
row.names(accuracy) <- c("mod_rf :in sample","        out of sample",
                         "mod_gbm:in sample","        out of sample",
                         "mod_qda:in sample","        out of sample")
accuracy <- round(accuracy[,c(1,3,4,2)],3)
accuracy
```

Predicting results
------------------



```{r, echo=FALSE}
right_answer <- factor(c("B","A","B","A","A","E","D","B","A","A",
                         "B","C","B","A","E","E","A","B","B","B"))
accu_rf <- round(sum(predict(mod_rf, testing) == right_answer) / length(right_answer), 2)
accu_gbm <- round(sum(predict(mod_gbm, testing) == right_answer) / length(right_answer), 2)
accu_qda <- round(sum(predict(mod_qda, testing) == right_answer) / length(right_answer), 2)
accu_rf; accu_gbm; accu_qda
```


